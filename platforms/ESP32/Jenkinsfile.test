pipeline {
    agent none

    parameters {
        string(
            name: 'BUILD_JOB_NAME',
            defaultValue: 'platforms/ESP32/ats-fw-esp32-demo',
            description: 'Name of the build job that produced the firmware (with folder path)'
        )
        string(
            name: 'BUILD_NUMBER',
            defaultValue: '',
            description: 'Build number of the firmware to test'
        )
        string(
            name: 'ATS_NODE_LABEL',
            defaultValue: 'raspi-ats-01',
            description: 'Label for ATS node pool (e.g., ats-node, ats-pi-01)'
        )
        choice(
            name: 'IMAGE_SOURCE',
            choices: ['registry', 'build'],
            description: 'How to get ats-node-test image: pull from registry or build on agent'
        )
        string(
            name: 'ATS_NODE_TEST_IMAGE',
            defaultValue: 'ghcr.io/picopiece/ats-node-test:latest',
            description: 'Docker image name for ATS node test container (registry or local)'
        )
        string(
            name: 'GHCR_CREDENTIALS_ID',
            defaultValue: '',
            description: 'Jenkins Credentials ID for GitHub Container Registry (GHCR) login (e.g., ghcr-creds). Leave empty if image is public.'
        )
        string(
            name: 'TEST_REPO_URL',
            defaultValue: 'https://github.com/PicoPiece/ats-test-esp32-demo.git',
            description: 'Git URL of the test framework repository'
        )
        string(
            name: 'TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of the test framework repository to use'
        )
    }

    environment {
        WORKSPACE_DIR = "workspace"
        RESULTS_DIR = "results"
        TEST_REPO_DIR = "ats-test-esp32-demo"
    }

    stages {
        stage('Prepare Workspace') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                script {
                    if (!params.BUILD_NUMBER || params.BUILD_NUMBER == '') {
                        error("BUILD_NUMBER parameter is required")
                    }
                    
                    // Create workspace directory
                    sh """
                        mkdir -p ${WORKSPACE_DIR}
                        cd ${WORKSPACE_DIR}
                    """
                    
                    // Copy firmware artifacts from build job
                    echo "üì• Copying firmware artifacts from ${params.BUILD_JOB_NAME} #${params.BUILD_NUMBER}"
                    
                    // Copy artifacts in two steps to ensure both are copied
                    copyArtifacts(
                        projectName: params.BUILD_JOB_NAME,
                        selector: [
                            $class: 'SpecificBuildSelector',
                            buildNumber: params.BUILD_NUMBER.toString()
                        ],
                        filter: "*.bin",
                        target: WORKSPACE_DIR,
                        flatten: true
                    )
                    
                    copyArtifacts(
                        projectName: params.BUILD_JOB_NAME,
                        selector: [
                            $class: 'SpecificBuildSelector',
                            buildNumber: params.BUILD_NUMBER.toString()
                        ],
                        filter: "ats-manifest.yaml",
                        target: WORKSPACE_DIR,
                        flatten: true
                    )
                    
                    // Verify artifacts were copied
                    sh """
                        echo "üì¶ Verifying copied artifacts..."
                        echo "   Workspace directory: ${WORKSPACE_DIR}"
                        echo "   Current directory: \$(pwd)"
                        echo ""
                        echo "   All files in workspace:"
                        ls -lah ${WORKSPACE_DIR}/ || true
                        echo ""
                        echo "   Firmware binaries:"
                        ls -lh ${WORKSPACE_DIR}/*.bin 2>/dev/null || echo "   ‚ö†Ô∏è  No .bin files found"
                        echo ""
                        echo "   Manifest file:"
                        if [ -f ${WORKSPACE_DIR}/ats-manifest.yaml ]; then
                            echo "   ‚úÖ ats-manifest.yaml found"
                            ls -lh ${WORKSPACE_DIR}/ats-manifest.yaml
                        else
                            echo "   ‚ùå ats-manifest.yaml NOT found"
                            echo "   This will cause the test stage to fail!"
                        fi
                        echo ""
                    """
                    
                    // Checkout test framework
                    echo "üì¶ Checking out test framework: ${params.TEST_REPO_URL}"
                    dir(WORKSPACE_DIR) {
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.TEST_REPO_BRANCH}"]],
                            doGenerateSubmoduleConfigurations: false,
                            extensions: [[
                                $class: 'RelativeTargetDirectory',
                                relativeTargetDir: TEST_REPO_DIR
                            ]],
                            submoduleCfg: [],
                            userRemoteConfigs: [[
                                url: params.TEST_REPO_URL,
                                credentialsId: ''
                            ]]
                        ])
                    }
                    
                    // Verify workspace structure and fail if manifest is missing
                    sh """
                        echo "‚úÖ Final workspace verification:"
                        echo "   Workspace: ${WORKSPACE_DIR}"
                        ls -lah ${WORKSPACE_DIR}/ || true
                        echo ""
                        echo "üìã Manifest verification:"
                        if [ -f ${WORKSPACE_DIR}/ats-manifest.yaml ]; then
                            echo "‚úÖ Manifest found:"
                            cat ${WORKSPACE_DIR}/ats-manifest.yaml
                            echo ""
                            echo "‚úÖ Workspace preparation completed successfully"
                        else
                            echo "‚ùå ERROR: Manifest NOT found in ${WORKSPACE_DIR}/"
                            echo ""
                            echo "   Troubleshooting:"
                            echo "   1. Check if build job '${params.BUILD_JOB_NAME}' #${params.BUILD_NUMBER} exists"
                            echo "   2. Verify build job archived 'ats-manifest.yaml'"
                            echo "   3. Check Jenkins console for copyArtifacts errors"
                            echo "   4. Verify BUILD_NUMBER parameter is correct"
                            echo ""
                            echo "   Current workspace contents:"
                            ls -la ${WORKSPACE_DIR}/ || true
                            echo ""
                            exit 1
                        fi
                    """
                }
            }
        }

        stage('Prepare ATS Node Test Container') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                script {
                    if (params.IMAGE_SOURCE == 'registry') {
                        // Option 1: Pull from registry (fast, recommended)
                        echo "üì• Pulling ATS node test image from registry..."
                        echo "   Image: ${params.ATS_NODE_TEST_IMAGE}"
                        
                        sh """
                            echo "   Platform: \$(uname -m)"
                            echo "   Architecture: \$(uname -a)"
                        """
                        
                        // Use the full image name from parameter (should include registry)
                        def imageToPull = params.ATS_NODE_TEST_IMAGE
                        if (!imageToPull.contains('/') && !imageToPull.contains('.')) {
                            // If no registry prefix, assume it's just the name and add default
                            imageToPull = "ghcr.io/picopiece/${imageToPull}"
                            echo "   ‚ö†Ô∏è  Warning: Image name missing registry prefix, using: ${imageToPull}"
                        }
                        
                        // Try to login to GHCR if credentials are available (optional)
                        def ghcrCredsId = params.GHCR_CREDENTIALS_ID ?: env.GHCR_CREDENTIALS_ID ?: ''
                        def pullSuccess = false
                        
                        // #region agent log
                        echo """
                        üîç DEBUG: Credentials check
                          params.GHCR_CREDENTIALS_ID: ${params.GHCR_CREDENTIALS_ID ?: 'NOT SET'}
                          env.GHCR_CREDENTIALS_ID: ${env.GHCR_CREDENTIALS_ID ?: 'NOT SET'}
                          Final ghcrCredsId: ${ghcrCredsId ?: 'EMPTY'}
                          Image to pull: ${imageToPull}
                        """
                        // #endregion
                        
                        if (ghcrCredsId && ghcrCredsId != '') {
                            echo "üîê Attempting to login to GHCR with credentials ID: ${ghcrCredsId}"
                            try {
                                withCredentials([usernamePassword(credentialsId: ghcrCredsId,
                                                 usernameVariable: 'GHCR_USER',
                                                 passwordVariable: 'GHCR_TOKEN')]) {
                                    sh """
                                        # #region agent log
                                        echo "DEBUG: GHCR_USER length: \${#GHCR_USER}"
                                        echo "DEBUG: GHCR_TOKEN length: \${#GHCR_TOKEN}"
                                        echo "DEBUG: GHCR_TOKEN starts with: \${GHCR_TOKEN:0:10}..."
                                        # #endregion
                                        
                                        echo "Logging into GHCR..."
                                        LOGIN_OUTPUT=\$(echo "\$GHCR_TOKEN" | docker login ghcr.io -u "\$GHCR_USER" --password-stdin 2>&1)
                                        LOGIN_EXIT=\$?
                                        echo "\$LOGIN_OUTPUT"
                                        
                                        if [ \$LOGIN_EXIT -eq 0 ]; then
                                            echo "‚úÖ GHCR login successful"
                                            
                                            # #region agent log
                                            echo "DEBUG: Verifying login by checking docker config"
                                            cat ~/.docker/config.json | grep -A 2 "ghcr.io" || echo "DEBUG: No ghcr.io entry in docker config"
                                            # #endregion
                                            
                                            echo "üì• Pulling image: ${imageToPull}"
                                            PULL_OUTPUT=\$(docker pull ${imageToPull} 2>&1)
                                            PULL_EXIT=\$?
                                            echo "\$PULL_OUTPUT"
                                            
                                            if [ \$PULL_EXIT -eq 0 ]; then
                                                echo "‚úÖ Image pulled successfully"
                                                docker tag ${imageToPull} ${params.ATS_NODE_TEST_IMAGE} || true
                                            else
                                                echo "‚ùå Image pull failed with exit code: \$PULL_EXIT"
                                                exit 1
                                            fi
                                        else
                                            echo "‚ùå GHCR login failed with exit code: \$LOGIN_EXIT"
                                            echo "   Output: \$LOGIN_OUTPUT"
                                            exit 1
                                        fi
                                    """
                                }
                                pullSuccess = true
                                echo "‚úÖ Image pulled successfully: ${imageToPull}"
                            } catch (Exception e) {
                                echo "‚ö†Ô∏è  Failed to use credentials ${ghcrCredsId}: ${e.getMessage()}"
                                echo "   Exception type: ${e.getClass().getName()}"
                                echo "   Will try pull without login (works if image is public)"
                                
                                // Fallback: try pull without credentials
                                def pullOutput = sh(
                                    script: "docker pull ${imageToPull} 2>&1",
                                    returnStatus: true
                                )
                                pullSuccess = pullOutput == 0
                                
                                if (pullSuccess) {
                                    echo "‚úÖ Image pulled successfully (public): ${imageToPull}"
                                    sh "docker tag ${imageToPull} ${params.ATS_NODE_TEST_IMAGE} || true"
                                } else {
                                    echo "‚ùå Public pull also failed"
                                }
                            }
                        } else {
                            echo "‚ÑπÔ∏è  No GHCR credentials provided, trying public pull..."
                            // #region agent log
                            echo "DEBUG: Attempting public pull for: ${imageToPull}"
                            echo "DEBUG: Platform: \$(uname -m)"
                            echo "DEBUG: Checking if image exists and is public..."
                            // #endregion
                            
                            // Try to pull - if fails, provide clear guidance
                            def pullScript = """
                                PULL_OUTPUT=\$(docker pull ${imageToPull} 2>&1)
                                PULL_EXIT=\$?
                                echo "\$PULL_OUTPUT"
                                
                                if [ \$PULL_EXIT -ne 0 ]; then
                                    echo ""
                                    echo "‚ùå Public pull failed"
                                    echo ""
                                    echo "üîç Error analysis:"
                                    if echo "\$PULL_OUTPUT" | grep -q "unauthorized"; then
                                        echo "   ‚úÖ CONFIRMED: Image is PRIVATE (requires authentication)"
                                        echo ""
                                        echo "   Solutions:"
                                        echo "   1. Make image public:"
                                        echo "      GitHub ‚Üí Packages ‚Üí ats-node-test ‚Üí Settings ‚Üí Change visibility ‚Üí Public"
                                        echo ""
                                        echo "   2. Use credentials:"
                                        echo "      - Set GHCR_CREDENTIALS_ID parameter in pipeline"
                                        echo "      - Or create credentials in Jenkins with read:packages scope"
                                    elif echo "\$PULL_OUTPUT" | grep -q "manifest unknown"; then
                                        echo "   ‚úÖ CONFIRMED: Image doesn't exist or wrong tag"
                                        echo "   Check: docker manifest inspect ${imageToPull}"
                                    elif echo "\$PULL_OUTPUT" | grep -q "no space"; then
                                        echo "   ‚úÖ CONFIRMED: Disk space issue"
                                    else
                                        echo "   Unknown error - see output above"
                                    fi
                                fi
                                
                                exit \$PULL_EXIT
                            """
                            
                            def pullOutput = sh(
                                script: pullScript,
                                returnStatus: true
                            )
                            pullSuccess = pullOutput == 0
                            
                            if (pullSuccess) {
                                echo "‚úÖ Image pulled successfully: ${imageToPull}"
                                sh "docker tag ${imageToPull} ${params.ATS_NODE_TEST_IMAGE} || true"
                            } else {
                                echo ""
                                echo "‚ö†Ô∏è  Cannot pull image - will fall back to building on agent"
                            }
                        }
                        
                        if (!pullSuccess) {
                            echo "‚ö†Ô∏è  Failed to pull image from registry"
                            echo ""
                            sh """
                                echo "   Error details:"
                                docker pull ${params.ATS_NODE_TEST_IMAGE} 2>&1 | head -5 || true
                                echo ""
                                echo "   Common reasons:"
                                echo "   1. Image is private and requires authentication"
                                echo "      ‚Üí Setup GHCR_CREDENTIALS_ID in Jenkins or make image public"
                                echo "   2. Image doesn't exist for this platform (\$(uname -m))"
                                echo "      ‚Üí Check registry for available platforms"
                                echo "   3. Network/registry connectivity issue"
                                echo "      ‚Üí Check network/firewall settings"
                                echo ""
                                echo "   Note: Falling back to local build (this may take longer)"
                                echo ""
                            """
                            echo "   Falling back to build on agent..."
                            // Fall back to build with hotfix
                            dir(WORKSPACE_DIR) {
                                sh """
                                    set -euo pipefail
                                    echo "üîç Current directory: \$(pwd)"
                                    # Compute absolute workspace path
                                    WORKSPACE_ABS=\$(pwd)
                                    echo "üîç WORKSPACE_ABS: \$WORKSPACE_ABS"
                                    echo ""
                                    
                                    # Ensure ats-ats-node repo exists under WORKSPACE_ABS
                                    if [ ! -d "\${WORKSPACE_ABS}/ats-ats-node" ]; then
                                        echo "üì¶ Cloning ats-ats-node into \${WORKSPACE_ABS}/ats-ats-node..."
                                        git clone https://github.com/PicoPiece/ats-ats-node.git ats-ats-node || {
                                            echo "‚ùå Failed to clone ats-ats-node"
                                            exit 1
                                        }
                                    else
                                        echo "üì¶ ats-ats-node already exists, pulling latest..."
                                        cd \${WORKSPACE_ABS}/ats-ats-node
                                        git pull origin main || echo "‚ö†Ô∏è  git pull failed, using existing code"
                                    fi
                                    
                                    # Verify directory and Dockerfile
                                    if [ -d "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test" ] && [ -f "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/Dockerfile" ]; then
                                        echo "üê≥ Build context ready: \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test"
                                        cd \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test
                                        
                                        # Check if buildx is available, if not disable BuildKit
                                        if docker buildx version > /dev/null 2>&1; then
                                            export DOCKER_BUILDKIT=1
                                            echo "üß∞ Building ATS node test image with BuildKit..."
                                        else
                                            echo "‚ö†Ô∏è  BuildKit/buildx not available, using legacy builder..."
                                            unset DOCKER_BUILDKIT || true
                                        fi
                                        docker build --pull -t ${params.ATS_NODE_TEST_IMAGE} .
                                        echo "‚úÖ Container built: ${params.ATS_NODE_TEST_IMAGE}"
                                    else
                                        echo "‚ùå ERROR: Dockerfile not found at expected location: \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/Dockerfile"
                                        echo "Repository layout:"
                                        ls -lah \${WORKSPACE_ABS}/ats-ats-node || true
                                        exit 1
                                    fi
                                """
                            }
                        }
                    } else {
                        // Option 2: Build on agent (slow, but works without registry)
                        echo "üî® Building ATS node test container on agent..."
                        dir(WORKSPACE_DIR) {
                            sh """
                                set -euo pipefail
                                echo "üîç Current directory: \$(pwd)"
                                # Compute absolute workspace path
                                WORKSPACE_ABS=\$(pwd)
                                echo "üîç WORKSPACE_ABS: \$WORKSPACE_ABS"
                                echo ""
                                
                                # Ensure ats-ats-node repo exists under WORKSPACE_ABS
                                if [ ! -d "\${WORKSPACE_ABS}/ats-ats-node" ]; then
                                    echo "üì¶ Cloning ats-ats-node into \${WORKSPACE_ABS}/ats-ats-node..."
                                    git clone https://github.com/PicoPiece/ats-ats-node.git ats-ats-node || {
                                        echo "‚ùå Failed to clone ats-ats-node"
                                        exit 1
                                    }
                                else
                                    echo "üì¶ ats-ats-node already exists, pulling latest..."
                                    cd \${WORKSPACE_ABS}/ats-ats-node
                                    git pull origin main || echo "‚ö†Ô∏è  git pull failed, using existing code"
                                fi
                                
                                # Verify directory and Dockerfile
                                if [ -d "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test" ] && [ -f "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/Dockerfile" ]; then
                                    echo "üê≥ Build context ready: \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test"
                                    cd \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test
                                    
                                    # Check if buildx is available, if not disable BuildKit
                                    if docker buildx version > /dev/null 2>&1; then
                                        export DOCKER_BUILDKIT=1
                                        echo "üß∞ Building ATS node test image with BuildKit..."
                                    else
                                        echo "‚ö†Ô∏è  BuildKit/buildx not available, using legacy builder..."
                                        unset DOCKER_BUILDKIT || true
                                    fi
                                    docker build --pull -t ${params.ATS_NODE_TEST_IMAGE} .
                                    echo "‚úÖ Container built: ${params.ATS_NODE_TEST_IMAGE}"
                                else
                                    echo "‚ùå ERROR: Dockerfile not found at expected location: \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/Dockerfile"
                                    echo "Repository layout:"
                                    ls -lah \${WORKSPACE_ABS}/ats-ats-node || true
                                    exit 1
                                fi
                            """
                        }
                    }
                }
            }
        }

        stage('Run ATS Tests') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    sh """
                        echo "üöÄ [ATS] Running test execution container"
                        echo "üìã Image: ${params.ATS_NODE_TEST_IMAGE}"
                        echo "üìÅ Workspace: \$(pwd)"
                        
                        # Verify workspace contents before running container
                        echo "üì¶ Workspace contents:"
                        ls -lah \$(pwd)/
                        echo ""
                        
                        # Verify manifest exists
                        if [ ! -f ats-manifest.yaml ]; then
                            echo "‚ùå ERROR: ats-manifest.yaml not found in workspace!"
                            echo "   Expected path: \$(pwd)/ats-manifest.yaml"
                            echo "   Current directory: \$(pwd)"
                            echo "   Files in workspace:"
                            ls -lah \$(pwd)/ || true
                            echo ""
                            echo "   This usually means:"
                            echo "   1. Build job did not archive ats-manifest.yaml"
                            echo "   2. copyArtifacts failed in Prepare Workspace stage"
                            echo "   3. Wrong BUILD_NUMBER parameter"
                            exit 1
                        fi
                        
                        echo "‚úÖ Manifest found: \$(pwd)/ats-manifest.yaml"
                        echo "üìã Manifest content:"
                        cat ats-manifest.yaml
                        echo ""
                        
                        # Verify firmware binary exists
                        FW_BIN=\$(ls *.bin 2>/dev/null | head -1)
                        if [ -z "\$FW_BIN" ]; then
                            echo "‚ö†Ô∏è  Warning: No .bin firmware file found in workspace"
                        else
                            echo "‚úÖ Firmware binary found: \$FW_BIN"
                        fi
                        echo ""
                        
                        # Create results directory
                        mkdir -p ${RESULTS_DIR}
                        
                        # Ensure manifest and directory are readable by container
                        chmod 644 ats-manifest.yaml || true
                        chmod 755 . || true  # Ensure directory is traversable
                        chown \$(id -u):\$(id -g) ats-manifest.yaml 2>/dev/null || true
                        echo "üîç File permissions on host:"
                        ls -lah ats-manifest.yaml
                        echo "üîç Directory permissions:"
                        ls -ld .
                        echo ""
                        
                        # CRITICAL: Jenkins agent runs in a container, and we're running Docker inside that container
                        # This is a "Docker-in-Docker" scenario where we need to mount from the HOST filesystem
                        # 
                        # Agent container setup (from start-agent.sh):
                        #   -v /home/jenkins:/home/jenkins/agent (host -> container)
                        #   -v /var/run/docker.sock:/var/run/docker.sock
                        #
                        # So if we're at /home/jenkins/workspace/... in agent container,
                        # the HOST path is also /home/jenkins/workspace/... (same path on host)
                        #
                        # However, Docker inside container needs to mount from HOST, not container filesystem
                        # Solution: Use the path as-is since agent container mounts host /home/jenkins directly
                        
                        WORKSPACE_ABS=\$(pwd)
                        echo "üîç Current directory (in agent container): \${WORKSPACE_ABS}"
                        
                        # Verify we can see files from agent container perspective
                        echo "üîç Files visible from agent container:"
                        ls -lah \${WORKSPACE_ABS}/ | head -10
                        echo ""
                        
                        # Since agent container mounts /home/jenkins from host, the path should work
                        # But we need to ensure Docker can access it. Try to find the actual host mount point
                        # Check if we're in a container by looking at /.dockerenv or /proc/1/cgroup
                        if [ -f /.dockerenv ] || grep -qa docker /proc/1/cgroup 2>/dev/null; then
                            echo "üîç Running inside container (Jenkins agent)"
                            echo "   Agent container should have mounted host /home/jenkins"
                            echo "   Using path as-is for Docker mount: \${WORKSPACE_ABS}"
                        else
                            echo "üîç Running directly on host"
                            echo "   Using path as-is: \${WORKSPACE_ABS}"
                        fi
                        
                        # CRITICAL FIX for Docker-in-Docker: Use Docker volumes instead of bind mounts
                        # When Docker runs inside a container, bind mounts from container filesystem don't work
                        # Solution: Create a Docker volume and copy files into it
                        
                        echo "üîç Detected Docker-in-Docker scenario - using Docker volume instead of bind mount"
                        echo ""
                        
                        # Create a named Docker volume
                        WORKSPACE_VOLUME="jenkins-workspace-\$(date +%s)"
                        echo "üì¶ Creating Docker volume: \${WORKSPACE_VOLUME}"
                        docker volume create \${WORKSPACE_VOLUME} || {
                            echo "‚ùå Failed to create Docker volume"
                            exit 1
                        }
                        echo "‚úÖ Docker volume created"
                        echo ""
                        
                        # Copy files into the volume using tar pipe (works in Docker-in-Docker)
                        # This avoids bind mount which doesn't work in nested containers
                        echo "üìã Copying workspace files into Docker volume using tar pipe..."
                        echo "   Source: \${WORKSPACE_ABS}"
                        echo "   Volume: \${WORKSPACE_VOLUME}"
                        echo ""
                        
                        # Method: tar from workspace -> pipe -> tar into volume container
                        # This works because we're copying from container filesystem, not mounting
                        cd \${WORKSPACE_ABS}
                        tar -czf - . | docker run --rm -i \\
                            -v \${WORKSPACE_VOLUME}:/workspace \\
                            alpine:latest sh -c "
                                echo 'Extracting files into volume...'
                                cd /workspace
                                tar -xzf - || {
                                    echo '‚ùå Failed to extract files'
                                    exit 1
                                }
                                echo '‚úÖ Files extracted successfully'
                                echo ''
                                echo 'Verifying files in volume:'
                                ls -lah /workspace/ | head -10
                                echo ''
                                echo 'Verifying manifest file:'
                                test -f /workspace/ats-manifest.yaml && echo '‚úÖ Manifest file exists' || echo '‚ùå Manifest file missing'
                                echo ''
                                echo 'File count:'
                                find /workspace -type f | wc -l
                            " || {
                            echo "‚ùå Failed to copy files into volume"
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || true
                            exit 1
                        }
                        echo ""
                        
                        # Verify volume has files
                        echo "üîç Verifying volume contents..."
                        VOLUME_TEST=\$(docker run --rm -v \${WORKSPACE_VOLUME}:/workspace alpine:latest sh -c "test -f /workspace/ats-manifest.yaml && echo 'FILE_EXISTS' || echo 'FILE_MISSING'" 2>&1)
                        
                        if echo "\$VOLUME_TEST" | grep -q "FILE_EXISTS"; then
                            echo "‚úÖ Volume test PASSED - files are accessible in volume"
                            echo "   File content preview:"
                            docker run --rm -v \${WORKSPACE_VOLUME}:/workspace alpine:latest head -5 /workspace/ats-manifest.yaml 2>&1 || true
                            echo ""
                            echo "‚úÖ Using Docker volume: \${WORKSPACE_VOLUME}"
                            USE_VOLUME=true
                        else
                            echo "‚ùå Volume test FAILED"
                            echo "   Test output: \$VOLUME_TEST"
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || true
                            exit 1
                        fi
                        echo ""
                        
                        # Run test container with workspace mount
                        # Use Docker volume if we're in Docker-in-Docker scenario, otherwise use bind mount
                        echo "üöÄ Running ATS test container..."
                        
                        if [ "\${USE_VOLUME}" = "true" ]; then
                            echo "   Using Docker volume: \${WORKSPACE_VOLUME} -> /workspace"
                            docker run --rm --privileged \\
                                -v \${WORKSPACE_VOLUME}:/workspace \\
                                -v /dev:/dev \\
                                -v /sys/class/gpio:/sys/class/gpio:ro \\
                                -v /dev/gpiomem:/dev/gpiomem \\
                                -e MANIFEST_PATH=/workspace/ats-manifest.yaml \\
                                -e RESULTS_DIR=/workspace/${RESULTS_DIR} \\
                                ${params.ATS_NODE_TEST_IMAGE}
                            
                            EXIT_CODE=\$?
                            
                            # Verify results exist in volume BEFORE copying
                            echo ""
                            echo "üîç Verifying results in Docker volume before copy..."
                            docker run --rm \\
                                -v \${WORKSPACE_VOLUME}:/workspace:ro \\
                                alpine:latest sh -c "
                                    echo '   Checking volume contents:'
                                    ls -lah /workspace/ || true
                                    echo ''
                                    if [ -d /workspace/${RESULTS_DIR} ]; then
                                        echo '   ‚úÖ Results directory exists in volume'
                                        echo '   Results files:'
                                        ls -lah /workspace/${RESULTS_DIR}/ || true
                                        echo ''
                                        FILE_COUNT=\$(find /workspace/${RESULTS_DIR} -type f 2>/dev/null | wc -l)
                                        echo \"   File count: \${FILE_COUNT}\"
                                        exit 0
                                    else
                                        echo '   ‚ö†Ô∏è  Results directory NOT found in volume'
                                        echo '   Volume root contents:'
                                        find /workspace -maxdepth 2 -type d 2>/dev/null | head -10 || true
                                        exit 1
                                    fi
                                " || {
                                echo "‚ö†Ô∏è  Results not found in volume - test may have failed or results not written"
                                echo "   This is not necessarily an error if test failed"
                            }
                            
                            # Copy results back from volume to workspace
                            echo ""
                            echo "üì¶ Copying results back from Docker volume..."
                            # Get current directory (should be Jenkins workspace)
                            CURRENT_DIR=\$(pwd)
                            echo "   Current directory: \${CURRENT_DIR}"
                            echo "   Target results dir: \${CURRENT_DIR}/${RESULTS_DIR}"
                            
                            # Ensure results directory exists before copying
                            mkdir -p ${RESULTS_DIR}
                            chmod 755 ${RESULTS_DIR} || true
                            rm -f ${RESULTS_DIR}/* 2>/dev/null || true
                            
                            # CRITICAL: Use tar pipe to copy files directly from volume to host
                            # This works even when Jenkins agent is in a container
                            echo "   Using tar pipe to copy files from volume to host..."
                            
                            # First, verify source files exist
                            echo "   Verifying source files in volume..."
                            docker run --rm \\
                                -v \${WORKSPACE_VOLUME}:/source:ro \\
                                alpine:latest sh -c "
                                    if [ -d /source/${RESULTS_DIR} ]; then
                                        echo '   Source files in volume:'
                                        ls -lah /source/${RESULTS_DIR}/ || true
                                        echo ''
                                        FILE_COUNT=\$(find /source/${RESULTS_DIR} -type f 2>/dev/null | wc -l)
                                        echo \"   Found \${FILE_COUNT} files to copy\"
                                        exit 0
                                    else
                                        echo '‚ö†Ô∏è  Results directory not found in volume: /source/${RESULTS_DIR}' >&2
                                        echo '   Volume root contents:' >&2
                                        ls -la /source/ 2>&1 || true
                                        exit 1
                                    fi
                                " || {
                                echo "‚ùå Results directory not found in volume"
                                echo "   Checking volume contents..."
                                docker run --rm -v \${WORKSPACE_VOLUME}:/source:ro alpine:latest ls -la /source/ || true
                                exit 1
                            }
                            
                            # Create tar archive (redirect echo to stderr, only tar to stdout)
                            echo "   Creating tar archive from volume..."
                            docker run --rm \\
                                -v \${WORKSPACE_VOLUME}:/source:ro \\
                                alpine:latest sh -c "
                                    if [ -d /source/${RESULTS_DIR} ]; then
                                        cd /source/${RESULTS_DIR}
                                        tar -czf - . 2>&1
                                    else
                                        echo '‚ö†Ô∏è  Results directory not found' >&2
                                        exit 1
                                    fi
                                " > ${RESULTS_DIR}/results.tar.gz 2>${RESULTS_DIR}/tar_errors.log || {
                                echo "‚ùå Failed to create tar from volume"
                                echo "   Error log:"
                                cat ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                                exit 1
                            }
                            
                            # Verify tar file was created and has content
                            TAR_SIZE=\$(stat -c%s ${RESULTS_DIR}/results.tar.gz 2>/dev/null || echo "0")
                            if [ "\${TAR_SIZE}" -eq 0 ]; then
                                echo "‚ùå Tar file is empty"
                                cat ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                                exit 1
                            fi
                            echo "   Tar file created: \${TAR_SIZE} bytes"
                            rm -f ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                            
                            # Extract tar archive to results directory
                            echo "   Extracting tar archive..."
                            cd ${RESULTS_DIR}
                            tar -xzf results.tar.gz 2>&1 || {
                                echo "‚ùå Failed to extract tar archive"
                                echo "   Tar file size: \${TAR_SIZE} bytes"
                                file results.tar.gz || true
                                exit 1
                            }
                            rm -f results.tar.gz 2>/dev/null || true
                            
                            # Verify files were copied
                            echo ""
                            echo "‚úÖ Results copy completed"
                            FILE_COUNT=\$(find ${RESULTS_DIR} -type f 2>/dev/null | wc -l)
                            echo "   Files in Jenkins workspace: \${FILE_COUNT}"
                            if [ "\${FILE_COUNT}" -gt 0 ]; then
                                echo "   Files:"
                                ls -lah ${RESULTS_DIR}/ || true
                            else
                                echo "   ‚ùå No files found - copy failed"
                                exit 1
                            fi
                            
                            # CRITICAL: Fix ownership and permissions AFTER copy
                            # Files are owned by root in container, need to fix for Jenkins user
                            echo ""
                            echo "üîß Fixing file ownership and permissions..."
                            chown -R \$(id -u):\$(id -g) ${RESULTS_DIR}/ 2>/dev/null || true
                            # Fix permissions for files (not directory)
                            find ${RESULTS_DIR} -type f -exec chmod 644 {} \\; 2>/dev/null || true
                            find ${RESULTS_DIR} -type d -exec chmod 755 {} \\; 2>/dev/null || true
                            
                            # Verify files are in Jenkins workspace IMMEDIATELY after copy
                            echo ""
                            echo "üîç Verifying results in Jenkins workspace:"
                            echo "   Directory: \$(pwd)/${RESULTS_DIR}"
                            echo "   Absolute path: \${CURRENT_DIR}/${RESULTS_DIR}"
                            
                            # Check if directory exists
                            if [ ! -d "${RESULTS_DIR}" ]; then
                                echo "   ‚ùå Results directory does not exist!"
                                exit 1
                            fi
                            
                            echo "   ‚úÖ Results directory exists"
                            
                            # List directory contents first
                            echo "   Directory listing:"
                            ls -lah ${RESULTS_DIR}/ || true
                            
                            # Count files
                            FILE_COUNT=\$(find ${RESULTS_DIR} -type f 2>/dev/null | wc -l)
                            echo "   File count: \${FILE_COUNT}"
                            
                            if [ "\${FILE_COUNT}" -gt 0 ]; then
                                echo "   ‚úÖ Files found:"
                                find ${RESULTS_DIR} -type f -exec ls -lh {} \\; || true
                                
                                # Verify each expected file exists
                                echo ""
                                echo "   üìã Verifying expected files:"
                                for file in ats-summary.json boot_messages.log junit.xml meta.yaml uart_boot.log; do
                                    if [ -f "${RESULTS_DIR}/\${file}" ]; then
                                        FILE_SIZE=\$(stat -c%s "${RESULTS_DIR}/\${file}" 2>/dev/null || echo "0")
                                        echo "      ‚úÖ \${file}: \${FILE_SIZE} bytes"
                                    else
                                        echo "      ‚ùå \${file} MISSING"
                                    fi
                                done
                            else
                                echo "   ‚ùå No files found in results directory!"
                                echo "   This is a critical error - files were copied but not found"
                                echo "   Checking if files exist with different permissions:"
                                sudo ls -lah ${RESULTS_DIR}/ 2>/dev/null || ls -lah ${RESULTS_DIR}/ || true
                                exit 1
                            fi
                            
                            # Cleanup volume
                            echo "üßπ Cleaning up Docker volume..."
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || echo "‚ö†Ô∏è  Failed to remove volume (may be in use)"
                        else
                            echo "   Using bind mount: \${WORKSPACE_ABS} -> /workspace"
                            docker run --rm --privileged \\
                                -v "\${WORKSPACE_ABS}:/workspace" \\
                                -v /dev:/dev \\
                                -v /sys/class/gpio:/sys/class/gpio:ro \\
                                -v /dev/gpiomem:/dev/gpiomem \\
                                -e MANIFEST_PATH=/workspace/ats-manifest.yaml \\
                                -e RESULTS_DIR=/workspace/${RESULTS_DIR} \\
                                ${params.ATS_NODE_TEST_IMAGE}
                            
                            EXIT_CODE=\$?
                        fi
                        
                        if [ \$EXIT_CODE -eq 0 ]; then
                            echo "‚úÖ Test execution completed successfully"
                        else
                            echo "‚ùå Test execution failed with exit code: \$EXIT_CODE"
                        fi
                        
                        echo "üìä Results:"
                        ls -la ${RESULTS_DIR}/ || echo "   No results found"
                    """
                }
            }
        }

        stage('Archive Results') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    script {
                        // Verify results exist before archiving using shell commands (sandbox-safe)
                        def resultsExist = sh(
                            script: "test -d ${RESULTS_DIR} && echo 'EXISTS' || echo 'NOT_EXISTS'",
                            returnStdout: true
                        ).trim()
                        
                        if (resultsExist == 'EXISTS') {
                            echo "üì¶ Archiving results from ${RESULTS_DIR}"
                            
                            // List all files with sizes
                            def fileList = sh(
                                script: "find ${RESULTS_DIR} -type f -exec ls -lh {} \\; | awk '{print \$9, \"(\", \$5, \")\"}'",
                                returnStdout: true
                            ).trim()
                            
                            if (fileList) {
                                echo "   Files to archive:"
                                fileList.split('\n').each { line ->
                                    echo "   - ${line}"
                                }
                            } else {
                                echo "   ‚ö†Ô∏è  Results directory is empty"
                            }
                            
                            // Archive all result files
                            archiveArtifacts artifacts: "${RESULTS_DIR}/**", allowEmptyArchive: false
                            
                            // Publish JUnit test results
                            def junitFiles = sh(
                                script: "find ${RESULTS_DIR} -name '*.xml' -type f",
                                returnStdout: true
                            ).trim()
                            
                            if (junitFiles) {
                                echo "üìä Publishing JUnit test results:"
                                junitFiles.split('\n').each { file ->
                                    echo "   - ${file}"
                                }
                                junit testResults: "${RESULTS_DIR}/**/*.xml", allowEmptyResults: true
                            } else {
                                echo "   ‚ö†Ô∏è  No JUnit XML files found"
                            }
                        } else {
                            echo "   ‚ö†Ô∏è  Results directory does not exist: ${RESULTS_DIR}"
                            error("Results directory not found - cannot archive artifacts")
                        }
                    }
                }
            }
        }
    }

    post {
        success {
            echo "‚úÖ Firmware tested successfully on ATS node"
        }
        failure {
            echo "‚ùå Firmware test failed"
        }
        always {
            node("${params.ATS_NODE_LABEL}") {
                dir(WORKSPACE_DIR) {
                    archiveArtifacts artifacts: "${RESULTS_DIR}/**", allowEmptyArchive: true
                }
            }
        }
    }
}
